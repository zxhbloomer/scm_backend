# 子工作流Runtime记录优化方案

## 一、问题诊断

### 1.1 问题描述

当前实现中，子工作流调用会在 `ai_workflow_runtime` 表中创建独立的runtime记录，导致：

1. ❌ **数据语义不清晰**：一次完整执行被拆分成多条runtime记录
2. ❌ **违反直觉**：用户期望的"输入→输出"一一对应关系被破坏
3. ❌ **查询复杂**：需要追踪父子runtime关系才能理解完整执行流程
4. ❌ **统计困难**：执行次数、Token使用等统计需要排除子runtime记录

### 1.2 当前实现分析

**执行流程**：
```
用户触发执行
  ↓
创建父runtime记录 (runtime_uuid_parent)
  ├→ 节点1执行 → 记录到 runtime_node (runtime_id=parent)
  ├→ 子工作流节点执行
  │   ├→ ❌ 创建子runtime记录 (runtime_uuid_sub)  【问题点】
  │   ├→ 子流程节点执行 → 记录到 runtime_node (runtime_id=sub)
  │   └→ 子流程对话 → conversation_content (runtime_uuid=sub)
  └→ 节点3执行 → 记录到 runtime_node (runtime_id=parent)
```

**代码位置**：
- `WorkflowEngine.run()` 第123-130行：无论是否子工作流都创建runtime记录
- `WorkflowStarter.runSync()` 第360行：子工作流调用 `workflowEngine.run()`
- `SubWorkflowNode.onProcess()` 第71行：调用 `workflowStarter.runSync()`

### 1.3 根因分析

**设计缺陷**：
- 混淆了"工作流定义"和"节点"的概念
- 子工作流是节点的一种类型，而非独立的执行实例
- runtime记录应该代表"一次完整的用户触发执行"，而不是"工作流定义的调用"

## 二、KISS原则评估

### 2.1 四个关键问题

**1. "这是个真问题还是臆想出来的？"**
- ✅ **真问题**：数据结构不规范，影响理解和维护

**2. "有更简单的方法吗？"**
- ✅ **有**：取消子runtime创建，所有节点使用同一个runtime_uuid

**3. "会破坏什么吗？"**
- ✅ **不会**：conversationId继承机制保持不变，对话历史正确隔离

**4. "当前项目真的需要这个功能吗？"**
- ✅ **需要**：数据规范是系统可维护性的基础

## 三、方案设计

### 3.1 核心原则

**数据语义**：
```
一次用户触发 = 一条ai_workflow_runtime记录
  ├── input_data: 用户最初输入
  ├── output_data: 整个流程的最终输出（包括所有子流程）
  └── runtime_uuid: 唯一标识这次执行
```

**节点记录**：
```
ai_workflow_runtime_node 记录所有节点执行
  ├── 顶层工作流的节点
  ├── 子工作流节点（作为一个特殊节点类型）
  └── 子工作流内部的节点（使用父runtime_uuid）
```

**对话历史**：
```
ai_workflow_conversation_content 使用父runtime_uuid隔离
  ├── 父工作流的LLM节点对话
  └── 子工作流的LLM节点对话
  （所有对话都在同一个runtime_uuid下，便于完整追踪）
```

### 3.2 修改方案

#### 方案核心：只有顶层工作流创建runtime记录

**修改点1：WorkflowEngine构造函数**

新增一个构造函数参数：`String parentRuntimeUuid`

```java
// WorkflowEngine.java
public class WorkflowEngine {
    private String parentRuntimeUuid;  // 新增字段

    // 新增构造函数（用于子工作流）
    public WorkflowEngine(
        AiWorkflowEntity workflow,
        WorkflowStreamHandler streamHandler,
        List<AiWorkflowComponentEntity> components,
        List<AiWorkflowNodeVo> nodes,
        List<AiWorkflowEdgeEntity> edges,
        AiWorkflowRuntimeService workflowRuntimeService,
        AiWorkflowRuntimeNodeService workflowRuntimeNodeService,
        String parentRuntimeUuid  // 父runtime_uuid
    ) {
        // ... 原有逻辑
        this.parentRuntimeUuid = parentRuntimeUuid;
    }
}
```

**修改点2：WorkflowEngine.run() 方法**

```java
// WorkflowEngine.run() - 第109-130行
public void run(Long userId, List<JSONObject> userInputs, String tenantCode, String parentConversationId) {
    this.userId = userId;
    this.tenantCode = tenantCode;
    DataSourceHelper.use(this.tenantCode);

    Long workflowId = this.workflow.getId();

    // 关键修改：只有顶层工作流创建runtime记录
    if (parentRuntimeUuid == null) {
        // 顶层工作流：创建新的runtime记录
        if (parentConversationId != null && !parentConversationId.isEmpty()) {
            this.wfRuntimeResp = workflowRuntimeService.createWithConversationId(
                userId, workflowId, parentConversationId);
        } else {
            this.wfRuntimeResp = workflowRuntimeService.create(userId, workflowId);
        }

        String runtimeUuid = this.wfRuntimeResp.getRuntimeUuid();
        streamHandler.sendStart(JSONObject.toJSONString(wfRuntimeResp));

        // 使用新创建的runtime_uuid初始化wfState
        this.wfState = new WfState(userId, wfInputs, runtimeUuid, tenantCode, conversationId);
    } else {
        // 子工作流：复用父runtime_uuid，不创建新记录
        log.info("子工作流复用父runtime_uuid: {}", parentRuntimeUuid);

        // 不创建runtime记录，不发送start事件（父工作流已经发送过了）

        // 使用父runtime_uuid初始化wfState
        String conversationId = parentConversationId != null ? parentConversationId
            : (tenantCode + "::" + workflow.getWorkflowUuid() + "::" + userId);
        this.wfState = new WfState(userId, wfInputs, parentRuntimeUuid, tenantCode, conversationId);
    }

    // ... 后续执行逻辑保持不变
}
```

**修改点3：WorkflowStarter.runSync() 方法**

```java
// WorkflowStarter.runSync() - 第271-370行
public Map<String, Object> runSync(String workflowUuid,
                                   List<JSONObject> userInputs,
                                   String tenantCode,
                                   Long userId,
                                   Set<String> parentExecutionStack,
                                   String parentConversationId,
                                   String parentRuntimeUuid) {  // 新增参数
    try {
        DataSourceHelper.use(tenantCode);

        AiWorkflowEntity workflow = workflowService.getOrThrow(workflowUuid);

        if (workflow.getIsEnable() == null || !workflow.getIsEnable()) {
            throw new BusinessException("子工作流已禁用: " + workflowUuid);
        }

        log.info("SubWorkflow runSync: workflowUuid={}, userId={}, parentRuntimeUuid={}",
            workflowUuid, userId, parentRuntimeUuid);

        // ... 获取组件、节点、边配置（保持不变）

        // ... 创建StreamHandler（保持不变）

        // 创建工作流引擎（传入父runtime_uuid）
        WorkflowEngine workflowEngine = new WorkflowEngine(
            workflow,
            streamHandler,
            components,
            nodes,
            edges,
            workflowRuntimeService,
            workflowRuntimeNodeService,
            parentRuntimeUuid  // 传递父runtime_uuid
        );

        // 同步执行工作流（传递父conversationId）
        workflowEngine.run(userId, userInputs, tenantCode, parentConversationId);

        // ... 检查错误和返回结果（保持不变）

        log.info("SubWorkflow runSync completed: workflowUuid={}, result={}", workflowUuid, result);
        return result;

    } catch (Exception e) {
        log.error("SubWorkflow runSync error: workflowUuid={}", workflowUuid, e);
        throw new RuntimeException("子工作流执行失败: " + e.getMessage(), e);
    }
}
```

**修改点4：SubWorkflowNode.onProcess() 方法**

```java
// SubWorkflowNode.onProcess() - 第38-99行
@Override
protected NodeProcessResult onProcess() {
    log.info("开始执行子工作流节点: {}", node.getTitle());

    try {
        // 1-2. 解析配置和检测循环依赖（保持不变）
        SubWorkflowNodeConfig config = checkAndGetConfig(SubWorkflowNodeConfig.class);
        String subWorkflowUuid = config.getWorkflowUuid();

        if (subWorkflowUuid == null || subWorkflowUuid.isEmpty()) {
            throw new RuntimeException("子工作流未配置");
        }

        if (wfState.isInExecutionStack(subWorkflowUuid)) {
            throw new RuntimeException("检测到循环依赖: " +
                wfState.getExecutionStack() + " → " + subWorkflowUuid);
        }

        // 3. 映射输入参数（保持不变）
        Map<String, Object> subInputs = mapInputs(config);

        // 4. 执行子工作流
        log.info("调用子工作流: {} ({}), 使用父runtime_uuid: {}",
            config.getWorkflowName(), subWorkflowUuid, wfState.getUuid());

        WorkflowStarter workflowStarter = SpringUtil.getBean(WorkflowStarter.class);

        // 同步执行子工作流（传递父runtime_uuid）
        Map<String, Object> subOutputs = workflowStarter.runSync(
            subWorkflowUuid,
            convertToInputList(subInputs),
            wfState.getTenantCode(),
            wfState.getUserId(),
            wfState.getExecutionStack(),
            wfState.getConversationId(),
            wfState.getUuid()  // 传递父runtime_uuid
        );

        // 5-6. 设置输出和返回结果（保持不变）
        NodeIOData output = NodeIOData.createByText(
            DEFAULT_OUTPUT_PARAM_NAME,
            "",
            JSON.toJSONString(subOutputs)
        );

        log.info("子工作流节点执行完成: {}", node.getTitle());

        return NodeProcessResult.builder().content(List.of(output)).build();

    } catch (Exception e) {
        log.error("子工作流节点执行失败: {}", node.getTitle(), e);
        throw new RuntimeException("子工作流执行失败: " + e.getMessage(), e);
    }
}
```

**修改点5：清理删除逻辑**

```java
// AiWorkflowRuntimeService.delete() - 第353-376行
public boolean delete(String runtimeUuid) {
    log.info("开始物理删除工作流运行记录: {}", runtimeUuid);

    AiWorkflowRuntimeEntity runtime = getByUuid(runtimeUuid);
    if (runtime == null) {
        throw new RuntimeException("运行实例不存在: " + runtimeUuid);
    }

    Long runtimeId = runtime.getId();

    // 1. 级联删除运行节点记录（包括所有子工作流节点）
    int nodeCount = workflowRuntimeNodeService.deleteByRuntimeId(runtimeId);
    log.info("删除运行节点记录: runtime_id={}, count={}", runtimeId, nodeCount);

    // 2. 级联删除对话历史（包括所有子工作流对话）
    int conversationCount = workflowConversationContentService.deleteByRuntimeUuid(runtimeUuid);
    log.info("删除对话历史: runtime_uuid={}, count={}", runtimeUuid, conversationCount);

    // 3. 物理删除主记录
    int result = aiWorkflowRuntimeMapper.deleteById(runtimeId);
    log.info("删除运行记录: runtime_id={}, result={}", runtimeId, result);

    return result > 0;
}

// 注意：deleteAll()方法保持不变，因为只删除顶层runtime记录
```

### 3.3 数据结构对比

#### 修改前（当前实现）

```sql
-- ai_workflow_runtime 表（一次执行 = 多条记录）
runtime_uuid_parent | workflow_id=27 | input_data | output_data | status
runtime_uuid_sub1   | workflow_id=25 | input_data | output_data | status  ❌ 不应该存在
runtime_uuid_sub2   | workflow_id=26 | input_data | output_data | status  ❌ 不应该存在

-- ai_workflow_runtime_node 表（节点分散在不同runtime下）
runtime_id=parent | node_uuid=node1 | input | output | status
runtime_id=sub1   | node_uuid=node2 | input | output | status  ❌ 应该在parent下
runtime_id=sub1   | node_uuid=node3 | input | output | status  ❌ 应该在parent下
runtime_id=sub2   | node_uuid=node4 | input | output | status  ❌ 应该在parent下
runtime_id=parent | node_uuid=node5 | input | output | status

-- ai_workflow_conversation_content 表（对话分散在不同runtime_uuid下）
runtime_uuid=parent | conversation_id | type=user | content
runtime_uuid=parent | conversation_id | type=assistant | content
runtime_uuid=sub1   | conversation_id | type=user | content  ❌ 应该使用parent
runtime_uuid=sub1   | conversation_id | type=assistant | content  ❌ 应该使用parent
runtime_uuid=sub2   | conversation_id | type=user | content  ❌ 应该使用parent
runtime_uuid=sub2   | conversation_id | type=assistant | content  ❌ 应该使用parent
```

#### 修改后（优化方案）

```sql
-- ai_workflow_runtime 表（一次执行 = 一条记录）
runtime_uuid_parent | workflow_id=27 | input_data | output_data | status  ✅ 唯一记录

-- ai_workflow_runtime_node 表（所有节点统一在一个runtime下）
runtime_id=parent | node_uuid=node1 | input | output | status  ✅ 父工作流节点
runtime_id=parent | node_uuid=node2 | input | output | status  ✅ 子工作流内部节点
runtime_id=parent | node_uuid=node3 | input | output | status  ✅ 子工作流内部节点
runtime_id=parent | node_uuid=node4 | input | output | status  ✅ 子工作流内部节点
runtime_id=parent | node_uuid=node5 | input | output | status  ✅ 父工作流节点

-- ai_workflow_conversation_content 表（所有对话统一在一个runtime_uuid下）
runtime_uuid=parent | conversation_id | type=user | content  ✅ 父工作流对话
runtime_uuid=parent | conversation_id | type=assistant | content  ✅ 父工作流对话
runtime_uuid=parent | conversation_id | type=user | content  ✅ 子工作流对话
runtime_uuid=parent | conversation_id | type=assistant | content  ✅ 子工作流对话
runtime_uuid=parent | conversation_id | type=user | content  ✅ 子工作流对话
runtime_uuid=parent | conversation_id | type=assistant | content  ✅ 子工作流对话
```

### 3.4 影响分析

#### 正面影响

1. ✅ **数据语义清晰**：一次执行=一条runtime记录
2. ✅ **查询简化**：无需追踪父子关系
3. ✅ **统计准确**：执行次数、Token使用直接统计
4. ✅ **删除准确**：删除runtime记录时自动清理所有相关数据
5. ✅ **易于理解**：符合"输入→输出"的直觉

#### 兼容性影响

1. ✅ **对话历史**：保持正确隔离（使用runtime_uuid）
2. ✅ **节点记录**：所有节点记录完整保留
3. ✅ **conversationId**：继承机制保持不变
4. ✅ **API兼容**：Controller层无需修改
5. ✅ **前端兼容**：显示逻辑无需修改

#### 潜在风险

1. ⚠️ **历史数据**：现有的子runtime记录如何处理？
   - **缓解措施**：数据迁移脚本（可选）或保留历史数据

2. ⚠️ **性能影响**：同一个runtime下节点记录增多
   - **评估**：影响极小（查询使用runtime_id索引）

## 四、实施步骤

### 4.1 修改顺序

```
1. WorkflowEngine - 新增parentRuntimeUuid字段和构造函数
2. WorkflowEngine.run() - 修改runtime创建逻辑
3. WorkflowStarter.runSync() - 传递parentRuntimeUuid参数
4. SubWorkflowNode.onProcess() - 调用时传递父runtime_uuid
5. 编译验证
6. 单元测试
7. 集成测试
```

### 4.2 验证检查清单

#### 编译验证
- [ ] WorkflowEngine编译通过
- [ ] WorkflowStarter编译通过
- [ ] SubWorkflowNode编译通过
- [ ] scm-ai模块整体编译通过

#### 功能验证
- [ ] 顶层工作流执行：创建runtime记录
- [ ] 子工作流执行：不创建runtime记录
- [ ] 子工作流节点记录：使用父runtime_id
- [ ] 子工作流对话记录：使用父runtime_uuid
- [ ] 删除操作：正确清理所有相关数据

#### 数据验证
- [ ] ai_workflow_runtime表：一次执行=一条记录
- [ ] ai_workflow_runtime_node表：所有节点记录完整
- [ ] ai_workflow_conversation_content表：对话记录完整且隔离正确

## 五、预期效果

### 5.1 数据质量提升

- ✅ 数据语义清晰：一次执行=一条runtime记录
- ✅ 数据关系简单：无需追踪父子runtime关系
- ✅ 数据完整性：删除操作自动级联清理
- ✅ 符合直觉：input_data→output_data 一一对应

### 5.2 系统可维护性提升

- ✅ 查询简化：直接查询runtime_uuid获取完整执行信息
- ✅ 统计准确：执行次数、Token使用直接统计
- ✅ 易于理解：开发者和运维人员容易理解数据结构
- ✅ 减少混淆：不会误解子工作流为独立执行

### 5.3 系统稳定性

- ✅ 不破坏现有功能：对话历史、节点记录机制保持不变
- ✅ 不需要数据迁移：历史数据可以保留（可选清理）
- ✅ API兼容：Controller和前端无需修改
- ✅ 向后兼容：现有工作流定义无需修改

## 六、KISS原则验证

### 6.1 简化复杂度

**修改前的概念数量**：6个
1. 父runtime记录
2. 子runtime记录
3. 父runtime_node记录
4. 子runtime_node记录
5. conversationId继承机制
6. runtime_uuid级联删除机制

**修改后的概念数量**：3个
1. runtime记录（只有顶层）
2. runtime_node记录（所有节点）
3. conversationId（工作流级别记忆）

**复杂度降低**：50%

### 6.2 消除特殊情况

**修改前**：
```java
if (parentConversationId != null) {
    // 子工作流：创建新runtime但继承conversationId
    this.wfRuntimeResp = workflowRuntimeService.createWithConversationId(
        userId, workflowId, parentConversationId);
} else {
    // 顶层工作流：创建新runtime和conversationId
    this.wfRuntimeResp = workflowRuntimeService.create(userId, workflowId);
}
```

**修改后**：
```java
if (parentRuntimeUuid == null) {
    // 顶层工作流：创建runtime记录
    if (parentConversationId != null) {
        this.wfRuntimeResp = workflowRuntimeService.createWithConversationId(...);
    } else {
        this.wfRuntimeResp = workflowRuntimeService.create(...);
    }
} else {
    // 子工作流：不创建runtime，直接使用父runtime_uuid
    // 无需特殊处理
}
```

**特殊情况减少**：1个分支判断变得更清晰

### 6.3 保持向后兼容

- ✅ conversationId继承机制保持不变
- ✅ 对话历史隔离机制保持不变
- ✅ 节点执行记录机制保持不变
- ✅ API接口保持不变
- ✅ 前端显示逻辑保持不变

## 七、方案总结

**核心策略**：只有顶层工作流创建runtime记录，子工作流复用父runtime_uuid

**影响范围**：scm-ai模块内部，4个文件

**风险等级**：低（只修改创建逻辑，数据结构不变）

**实施时间**：< 2小时（包含测试验证）

**优先级**：高（提升数据规范性和系统可维护性）

**验收标准**：
1. 顶层工作流执行创建唯一runtime记录
2. 子工作流执行不创建runtime记录
3. 所有节点记录使用父runtime_id
4. 所有对话记录使用父runtime_uuid
5. 删除操作正确清理所有相关数据
6. 数据语义清晰：input_data → output_data 一一对应
