# MCP工具节点执行过程输出开关 - 开发设计方案

## 1. 需求概述

### 1.1 问题背景
在工作流执行过程中，MCP工具节点（如"权限判断工具"）的执行输出会通过SSE流式返回到前端聊天界面，造成中间处理信息污染用户界面。

### 1.2 需求描述
在MCP工具节点配置中增加"执行过程输出"开关：
- **开启（默认）**：当前行为，节点输出流式显示在聊天界面
- **关闭**：节点输出不显示在聊天界面，但数据仍传递给下游节点

### 1.3 关键约束
- 关闭流式输出时，**必须**保证数据能够正确传递给下游节点
- 默认值为"开启"，保证向后兼容

---

## 2. 完整调用链路分析

### 2.1 MCP工具节点执行流程图

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                        MCP工具节点执行调用链路                               │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌──────────────────┐                                                       │
│  │  WorkflowEngine  │  工作流引擎入口                                        │
│  └────────┬─────────┘                                                       │
│           │                                                                 │
│           ▼                                                                 │
│  ┌──────────────────┐                                                       │
│  │  McpToolNode     │  MCP工具节点                                           │
│  │  .onProcess()    │  scm-ai/.../node/mcptool/McpToolNode.java:49          │
│  └────────┬─────────┘                                                       │
│           │                                                                 │
│           │  1. 解析配置: McpToolNodeConfig                                  │
│           │  2. 构建prompt                                                   │
│           │  3. 获取modelName                                                │
│           ▼                                                                 │
│  ┌──────────────────┐                                                       │
│  │ WorkflowUtil     │  工作流工具类                                          │
│  │ .streamingInvoke │  scm-ai/.../workflow/WorkflowUtil.java:127            │
│  │  LLM()           │                                                       │
│  └────────┬─────────┘                                                       │
│           │                                                                 │
│           │  调用LLM，流式接收响应                                            │
│           ▼                                                                 │
│  ┌──────────────────────────────────────────────────────────┐               │
│  │  Reactor Stream 流式处理                                  │               │
│  │  .doOnNext(chatResponse -> {                             │               │
│  │      String content = chatResponse...getText();          │               │
│  │      fullResponse.append(content);  ← 【数据收集】        │               │
│  │                                                          │               │
│  │      if (wfState.getStreamHandler() != null) {           │               │
│  │          wfState.getStreamHandler()                      │               │
│  │              .sendNodeChunk(nodeUuid, content);          │               │
│  │      }                           ↑                       │               │
│  │                                  │                       │               │
│  │                         【SSE推送点】                     │               │
│  │                     WorkflowUtil.java:184/233            │               │
│  │  })                                                      │               │
│  └──────────────────────────────────────────────────────────┘               │
│           │                                                                 │
│           │  流完成后                                                        │
│           ▼                                                                 │
│  ┌──────────────────┐                                                       │
│  │  nodeState       │                                                       │
│  │  .getOutputs()   │  将完整响应写入节点输出                                 │
│  │  .add(output)    │  WorkflowUtil.java:259-260                            │
│  └────────┬─────────┘                                                       │
│           │                                                                 │
│           │  下游节点通过input_config引用此输出                               │
│           ▼                                                                 │
│  ┌──────────────────┐                                                       │
│  │  下游节点        │  如：大模型节点、分支判断节点                           │
│  │  (通过ref_inputs │                                                       │
│  │   获取数据)      │                                                       │
│  └──────────────────┘                                                       │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 2.2 关键发现

**SSE推送的唯一出口点**：`WorkflowUtil.java` 第184行和第233行的 `sendNodeChunk()` 调用

**数据传递机制**：
1. `fullResponse.append(content)` - 收集完整响应（第181行、230行）
2. `nodeState.getOutputs().add(output)` - 写入节点输出（第260行）
3. 下游节点通过 `input_config.ref_inputs` 引用上游输出

**结论**：只需在 `sendNodeChunk()` 调用前增加开关判断，不影响数据收集和传递。

---

## 3. 按文件设计

### 3.1 后端文件修改

#### 3.1.1 McpToolNodeConfig.java（修改）

**文件路径**：`scm-ai/src/main/java/com/xinyirun/scm/ai/workflow/node/mcptool/McpToolNodeConfig.java`

**修改内容**：增加 `showProcessOutput` 字段

```java
// 新增字段（在 modelName 字段后添加）

/**
 * 是否显示执行过程输出到chat流
 * true(默认): 流式输出显示在聊天界面
 * false: 不显示流式输出，但结果仍传递给下游节点
 */
@JSONField(name = "show_process_output")
private Boolean showProcessOutput = true;
```

#### 3.1.2 McpToolNode.java（修改）

**文件路径**：`scm-ai/src/main/java/com/xinyirun/scm/ai/workflow/node/mcptool/McpToolNode.java`

**修改内容**：第94行，传递静默模式参数

```java
// 原代码（第94行）
WorkflowUtil.streamingInvokeLLM(wfState, state, node, modelName, prompt);

// 修改为
boolean silentMode = config.getShowProcessOutput() != null && !config.getShowProcessOutput();
WorkflowUtil.streamingInvokeLLM(wfState, state, node, modelName, prompt, silentMode);
```

#### 3.1.3 WorkflowUtil.java（修改）

**文件路径**：`scm-ai/src/main/java/com/xinyirun/scm/ai/workflow/WorkflowUtil.java`

**修改内容**：

1. **修改方法签名**（第127行）：增加 `silentMode` 参数

```java
// 原签名
public static void streamingInvokeLLM(WfState wfState, WfNodeState nodeState, AiWorkflowNodeVo node,
                                       String modelName, String prompt)

// 修改为
public static void streamingInvokeLLM(WfState wfState, WfNodeState nodeState, AiWorkflowNodeVo node,
                                       String modelName, String prompt, boolean silentMode)
```

2. **修改第一处SSE推送**（第182-185行）：

```java
// 原代码
if (wfState.getStreamHandler() != null) {
    wfState.getStreamHandler().sendNodeChunk(node.getUuid(), content);
}

// 修改为
if (!silentMode && wfState.getStreamHandler() != null) {
    wfState.getStreamHandler().sendNodeChunk(node.getUuid(), content);
}
```

3. **修改第二处SSE推送**（第231-234行）：

```java
// 原代码
if (wfState.getStreamHandler() != null) {
    wfState.getStreamHandler().sendNodeChunk(node.getUuid(), content);
}

// 修改为
if (!silentMode && wfState.getStreamHandler() != null) {
    wfState.getStreamHandler().sendNodeChunk(node.getUuid(), content);
}
```

4. **增加重载方法**（保持向后兼容）：

```java
/**
 * 流式调用LLM（向后兼容版本，默认显示输出）
 */
public static void streamingInvokeLLM(WfState wfState, WfNodeState nodeState, AiWorkflowNodeVo node,
                                       String modelName, String prompt) {
    streamingInvokeLLM(wfState, nodeState, node, modelName, prompt, false);
}
```

#### 3.1.4 其他调用点检查

需要检查并更新其他调用 `streamingInvokeLLM` 的文件：
- `LLMAnswerNode.java` - 保持原调用（使用5参数版本，默认显示）
- `FaqExtractorNode.java` - 保持原调用
- `KeywordExtractorNode.java` - 保持原调用

这些节点不需要静默模式，使用向后兼容的5参数重载方法即可。

### 3.2 前端文件修改

#### 3.2.1 MCP工具节点属性面板（修改）

**文件路径**：`scm_frontend/src/components/70_ai/components/workflow/nodes/McpToolNodePanel.vue`（或类似名称）

**修改内容**：增加开关控件

```vue
<!-- 在节点属性表单中增加 -->
<el-form-item label="执行过程输出">
  <el-switch
    v-model="nodeConfig.show_process_output"
    active-text="显示"
    inactive-text="隐藏"
  />
  <div class="form-tip">关闭后，节点执行结果不会显示在对话中，但仍会传递给下游节点</div>
</el-form-item>
```

**数据初始化**：确保 `nodeConfig.show_process_output` 默认值为 `true`

### 3.3 数据库操作

本次修改不涉及数据库表结构变更。

配置数据存储在 `ai_workflow_node.node_config` JSON字段中，示例：

```json
{
  "tool_input": "调用 getPageButtonPermissions...",
  "model_name": "gj-deepseek",
  "show_process_output": false
}
```

---

## 4. KISS原则7问题回答

### 4.1 这是个真问题还是臆想出来的？
**✅ 真问题**。用户在测试工作流时实际遇到：MCP工具节点（权限判断工具）的执行输出显示在聊天界面中，污染了用户体验。

### 4.2 有更简单的方法吗？
**✅ 已是最简方案**：
- 1个配置字段
- 2处if判断
- 1个重载方法（向后兼容）
- 没有比这更简单的方案了

### 4.3 会破坏什么吗？
**✅ 零破坏**：
- 默认值为 `true`，保持现有行为
- 现有节点配置无此字段时，使用默认值
- 增加向后兼容的重载方法，其他调用点无需修改

### 4.4 当前项目真的需要这个功能吗？
**✅ 必要**。工作流中的中间处理节点（如权限判断、数据预处理）不应该将技术输出展示给最终用户，这是提升用户体验的基本需求。

### 4.5 这个问题过度设计了吗？有缺少必要信息吗？
**✅ 无过度设计**：
- 没有引入新的抽象层
- 没有创建新的类或接口
- 只是在现有代码上增加一个简单的布尔判断

### 4.6 话题是否模糊，是否会导致幻觉的产生？
**✅ 需求明确**：
- 用户明确指出问题（权限判断工具输出显示在chat中）
- 解决方案明确（增加开关控制是否流式输出）
- 边界条件明确（关闭时仍需传递数据给下游）

### 4.7 是否已经学习了关于代码实施的注意事项的内容？
**✅ 已学习并应用**：
- 使用 `@JSONField` 注解定义JSON字段映射
- 遵循现有代码风格（Boolean类型、默认值设置）
- 不使用 `Map<String, Object>`，使用具体的配置类

---

## 5. 风险分析和缓解措施

### 5.1 风险点

| 风险 | 可能性 | 影响 | 缓解措施 |
|------|--------|------|----------|
| 数据传递中断 | 低 | 高 | 代码设计确保 `fullResponse.append()` 和 `nodeState.getOutputs().add()` 不受影响 |
| 向后兼容问题 | 低 | 中 | 提供默认值 `true`，增加重载方法 |
| 前端配置丢失 | 低 | 低 | 前端初始化时设置默认值 |

### 5.2 测试验证要点

1. **功能测试**：
   - `show_process_output=true` 时，输出正常显示
   - `show_process_output=false` 时，输出不显示
   - `show_process_output` 未设置时，默认显示（向后兼容）

2. **数据流测试**：
   - 关闭输出后，下游节点仍能正确获取数据
   - 变量引用正常工作

---

## 6. 实施清单

### 6.1 后端修改文件

| 文件 | 修改类型 | 修改内容 |
|------|----------|----------|
| `McpToolNodeConfig.java` | 修改 | +1字段 `showProcessOutput` |
| `McpToolNode.java` | 修改 | +2行，传递 `silentMode` 参数 |
| `WorkflowUtil.java` | 修改 | +1参数 `silentMode`，+1重载方法，+2处if判断 |

### 6.2 前端修改文件

| 文件 | 修改类型 | 修改内容 |
|------|----------|----------|
| MCP工具节点属性面板 | 修改 | +1个开关控件 |

---

## 7. 支撑数据

### 7.1 代码分析数据

已分析的关键文件：
- `McpToolNode.java` (106行) - MCP工具节点实现
- `McpToolNodeConfig.java` (42行) - 节点配置类
- `WorkflowUtil.java` (421行) - 工作流工具类，包含流式调用逻辑

### 7.2 调用关系数据

`streamingInvokeLLM` 方法被以下文件调用：
1. `McpToolNode.java` - MCP工具节点 ← 本次需要传递静默参数
2. `LLMAnswerNode.java` - 答案生成节点 ← 保持默认（显示）
3. `FaqExtractorNode.java` - FAQ提取节点 ← 保持默认
4. `KeywordExtractorNode.java` - 关键词提取节点 ← 保持默认

---

**文档版本**：v1.0
**编写日期**：2025-12-11
**编写人**：Claude (SCM开发流程Agent)
