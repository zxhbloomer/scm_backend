# WorkflowEngine 并行分叉与汇聚优化方案

## 1. 需求概述

### 1.1 功能需求
实现SCM AI工作流引擎的以下4个功能：
1. **并行分叉 (1→N)**：一个节点连接多个下游节点并行执行
2. **汇聚 (N→1)**：多个节点汇聚到一个节点
3. **汇聚等待机制**：汇聚节点等待所有上游分支完成
4. **结果聚合**：汇聚节点收集并合并所有上游分支输出

### 1.2 约束条件
- 删除错误的旧逻辑，不考虑向后兼容性
- 性能完整参考Spring AI Alibaba实现
- 本次开发全部完成

---

## 2. 完整调用链路分析

### 2.1 当前SCM WorkflowEngine调用链路

```
WorkflowEngine.run()
    │
    ├── findStartAndEndNode() → 找到开始/结束节点
    │
    ├── getAndCheckUserInput() → 验证用户输入
    │
    ├── buildCompileNode() → [问题所在] 构建CompileNode树
    │       │
    │       ├── getUpstreamNodeUuids() → 获取上游节点
    │       │
    │       ├── pointToParallelBranch() → [错误] 判断是否并行分叉
    │       │
    │       ├── getOrCreateGraphCompileNode() → [错误] 创建子图包装
    │       │
    │       └── appendToNextNodes() → 添加下游节点
    │
    ├── buildStateGraph() → [问题所在] 构建StateGraph
    │       │
    │       ├── addNodeToStateGraph() → 添加节点
    │       │
    │       ├── addEdgeToStateGraph() → 添加边
    │       │
    │       └── [错误] 子图编译: subgraph.compile()
    │
    ├── mainStateGraph.compile() → 编译主图
    │
    └── exe() → 执行工作流
            │
            └── app.stream() → Spring AI Alibaba执行
```

### 2.2 Spring AI Alibaba正确的调用链路

```
StateGraph.addEdge(source, target) → 自动合并多目标边
    │
    └── Edge(sourceId, List<EdgeValue> targets)
            │
            └── targets.size() > 1 表示并行分叉

CompiledGraph 编译时处理:
    │
    ├── 检测 targets.size() > 1
    │
    ├── 自动创建 ParallelNode 包装所有并行分支
    │
    └── ParallelNode.AsyncParallelNodeAction.apply():
            │
            ├── 为每个分支创建 CompletableFuture
            │
            ├── CompletableFuture.allOf() 等待所有完成
            │
            └── processParallelResults() 合并结果
```

### 2.3 关键差异对比

| 方面 | SCM当前实现 | Spring AI Alibaba |
|------|-------------|-------------------|
| 并行分叉 | GraphCompileNode子图包装 | 自动Edge合并 |
| 汇聚等待 | 无（缺失） | CompletableFuture.allOf() |
| 结果聚合 | 无（缺失） | processParallelResults() |
| 复杂度 | 高（自定义子图逻辑） | 低（框架自动处理） |

---

## 3. 问题诊断和根因分析

### 3.1 根因分析

**核心问题**：SCM试图用`GraphCompileNode`子图方式"手动"实现并行，但这个设计从根本上是错误的。

Spring AI Alibaba的`addEdge()`方法**原生**支持：
- 同一源节点多次调用`addEdge(source, targetA)`, `addEdge(source, targetB)`会自动合并为并行分叉
- 多个源节点调用`addEdge(sourceA, target)`, `addEdge(sourceB, target)`会自动实现汇聚
- 框架在编译时自动创建`ParallelNode`处理并行执行和等待

**SCM的错误**：完全绕过了这个机制，自己用子图实现，导致：
1. 汇聚时没有等待机制
2. 结果无法正确聚合
3. 代码复杂度高且难以维护

### 3.2 需要删除的代码

| 文件 | 需要删除的内容 |
|------|---------------|
| WorkflowEngine.java | `nodeToParallelBranch` Map |
| WorkflowEngine.java | `rootToSubGraph` Map |
| WorkflowEngine.java | `buildCompileNode()` 方法 |
| WorkflowEngine.java | `getOrCreateGraphCompileNode()` 方法 |
| WorkflowEngine.java | `pointToParallelBranch()` 方法 |
| WorkflowEngine.java | `appendToNextNodes()` 方法 |
| WorkflowEngine.java | `CompileNode rootCompileNode` 使用 |
| GraphCompileNode.java | 整个类的使用（保留文件但不再使用） |
| CompileNode.java | 整个类的使用（保留文件但不再使用） |

---

## 4. 按文件设计

### 4.1 后端文件修改清单

#### 4.1.1 WorkflowEngine.java

**文件路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/workflow/WorkflowEngine.java`

**修改内容**:

1. **删除的成员变量**:
```java
// 删除以下变量
private final Map<String, String> rootToSubGraph = new HashMap<>();
private final Map<String, GraphCompileNode> nodeToParallelBranch = new HashMap<>();
```

2. **删除的方法**:
- `buildCompileNode(CompileNode parentNode, AiWorkflowNodeVo node)`
- `getOrCreateGraphCompileNode(String rootId)`
- `pointToParallelBranch(String nodeUuid)`
- `appendToNextNodes(CompileNode compileNode, CompileNode newNode)`

3. **修改的方法 - run()**:
```java
// 删除以下代码
CompileNode rootCompileNode = new CompileNode();
rootCompileNode.setId(startNode.getUuid());
buildCompileNode(rootCompileNode, startNode);

// 替换为
// 直接构建StateGraph，不使用CompileNode中间层
```

4. **重写的方法 - buildStateGraph()**:
```java
/**
 * 简化版buildStateGraph - 直接遍历边数据构建StateGraph
 * 让Spring AI Alibaba框架自动处理并行分叉和汇聚
 */
private void buildStateGraph(StateGraph stateGraph, AiWorkflowNodeVo startNode) throws GraphStateException {
    // 1. 添加所有节点到StateGraph
    for (AiWorkflowNodeVo node : wfNodes) {
        addNodeToStateGraph(stateGraph, node.getUuid());
    }

    // 2. 添加START到开始节点的边
    stateGraph.addEdge(START, startNode.getUuid());
    wfState.addEdge(START, startNode.getUuid());

    // 3. 遍历所有边，添加到StateGraph
    // Spring AI Alibaba会自动处理：
    // - 同源多目标 → 并行分叉（自动创建ParallelNode）
    // - 多源同目标 → 汇聚（自动等待所有上游完成）
    for (AiWorkflowEdgeEntity edge : wfEdges) {
        String source = edge.getSourceNodeUuid();
        String target = edge.getTargetNodeUuid();

        // 检查是否是条件分支边（有sourceHandle）
        if (StringUtils.isNotBlank(edge.getSourceHandle())) {
            // 条件分支边：使用ConditionalEdge
            // 由条件分支节点的runNode返回值决定走哪条边
            // 这里只记录边信息，实际条件判断在runNode中处理
            continue; // 条件边由addConditionalEdges单独处理
        }

        // 普通边：直接添加
        addEdgeToStateGraph(stateGraph, source, target);
    }

    // 4. 处理条件分支节点
    processConditionalEdges(stateGraph);

    // 5. 找到所有结束节点，添加到END的边
    for (AiWorkflowNodeVo node : wfNodes) {
        if (isEndNode(node)) {
            addEdgeToStateGraph(stateGraph, node.getUuid(), END);
        }
    }
}

/**
 * 处理条件分支边
 */
private void processConditionalEdges(StateGraph stateGraph) throws GraphStateException {
    // 找出所有条件分支节点（有带sourceHandle的出边）
    Map<String, List<AiWorkflowEdgeEntity>> conditionalEdgesMap = new HashMap<>();

    for (AiWorkflowEdgeEntity edge : wfEdges) {
        if (StringUtils.isNotBlank(edge.getSourceHandle())) {
            conditionalEdgesMap
                .computeIfAbsent(edge.getSourceNodeUuid(), k -> new ArrayList<>())
                .add(edge);
        }
    }

    // 为每个条件分支节点添加ConditionalEdge
    for (Map.Entry<String, List<AiWorkflowEdgeEntity>> entry : conditionalEdgesMap.entrySet()) {
        String sourceUuid = entry.getKey();
        List<AiWorkflowEdgeEntity> conditionalEdges = entry.getValue();

        // 构建条件映射
        Map<String, String> mappings = new HashMap<>();
        for (AiWorkflowEdgeEntity edge : conditionalEdges) {
            mappings.put(edge.getTargetNodeUuid(), edge.getTargetNodeUuid());
        }

        // 添加条件边
        stateGraph.addConditionalEdges(
            sourceUuid,
            edge_async(state -> state.data().get("next").toString()),
            mappings
        );
    }
}

/**
 * 判断是否是结束节点（没有出边的节点）
 */
private boolean isEndNode(AiWorkflowNodeVo node) {
    // 检查是否是End组件
    AiWorkflowComponentEntity component = components.stream()
        .filter(c -> c.getId().equals(node.getWorkflowComponentId()))
        .findFirst()
        .orElse(null);

    if (component != null && "End".equals(component.getName())) {
        return true;
    }

    // 检查是否没有出边
    boolean hasOutEdge = wfEdges.stream()
        .anyMatch(edge -> edge.getSourceNodeUuid().equals(node.getUuid()));

    return !hasOutEdge;
}
```

5. **保留的方法**（无需修改）:
- `addNodeToStateGraph()` - 保持原有逻辑
- `addEdgeToStateGraph()` - 保持原有逻辑
- `runNode()` - 保持原有逻辑
- `getUpstreamNodeUuids()` - 保留但可能不再使用
- `getDownstreamNodeUuids()` - 保留但可能不再使用

#### 4.1.2 不需要修改的文件

| 文件 | 说明 |
|------|------|
| GraphCompileNode.java | 保留文件，但不再使用 |
| CompileNode.java | 保留文件，但不再使用 |
| WfState.java | 无需修改 |
| WfNodeState.java | 无需修改 |

### 4.2 前端文件修改清单

**本次修改不涉及前端**，因为：
- 前端工作流编辑器已经正确保存了边数据
- 数据库中的`ai_workflow_edge`表结构正确
- 只需要后端正确解析和执行

---

## 5. 支撑数据和分析

### 5.1 实际工作流数据（workflow_id=31）

**并行分叉示例**:
| 源节点 | 目标节点数 | 目标节点 |
|--------|-----------|----------|
| 开始 | 3 | 法律应用条例审查、常规审查点、首部+尾部主体名称 |
| 首部+尾部主体名称 | 2 | 甲方名称一致性审查、乙方名称一致性审查 |
| 合规性审查分析 | 2 | 乙方企业天眼风险、甲方企业天眼风险 |

**汇聚示例**:
| 目标节点 | 源节点数 | 源节点 |
|----------|---------|--------|
| 企业风险总结 | 7 | 错误返回x2、法律有效性检查、条件分支、常规审查点、甲方/乙方企业天眼风险 |
| 数据确认 | 3 | 甲方名称一致性、乙方名称一致性x2 |

### 5.2 Spring AI Alibaba关键源码引用

**ParallelNode.java:264-271** - 等待所有分支完成:
```java
return CompletableFuture.allOf(futures.toArray(CompletableFuture[]::new)).thenApply(v -> {
    List<Map<String, Object>> results = futures.stream()
            .map(CompletableFuture::join)
            .collect(Collectors.toList());
    return processParallelResults(results, state, actions);
});
```

**StateGraph.java:383-401** - 自动合并多目标边:
```java
public StateGraph addEdge(String sourceId, String targetId) throws GraphStateException {
    var newEdge = new Edge(sourceId, new EdgeValue(targetId));
    int index = edges.elements.indexOf(newEdge);
    if (index >= 0) {
        // 同一源节点自动合并多个目标
        var newTargets = new ArrayList<>(edges.elements.get(index).targets());
        newTargets.add(newEdge.target());
        edges.elements.set(index, new Edge(sourceId, newTargets));
    } else {
        edges.elements.add(newEdge);
    }
    return this;
}
```

---

## 6. KISS原则7问题回答

### 问题1：这是个真问题还是臆想出来的？
**✅ 真问题**。当前SCM工作流引擎无法正确处理：
- 7个节点汇聚到"企业风险总结"节点的场景
- 汇聚节点可能在部分分支完成时就执行

### 问题2：有更简单的方法吗？
**✅ 已是最简方案**。直接使用Spring AI Alibaba原生的`addEdge()`机制，删除所有自定义的子图逻辑。

### 问题3：会破坏什么吗？
**✅ 无破坏风险**。
- 数据库结构不变
- 前端不变
- 只是后端执行逻辑优化

### 问题4：当前项目真的需要这个功能吗？
**✅ 必要**。合同审批工作流(id=31)已经在使用复杂的并行/汇聚拓扑，当前实现无法正确执行。

### 问题5：这个问题过度设计了吗？
**✅ 没有过度设计**。方案是删除复杂代码，用框架原生能力替代，实际上是**简化**设计。

### 问题6：话题是否模糊，是否会产生幻觉？
**✅ 不会**。有明确的：
- Spring AI Alibaba源码作为参考
- MySQL中的实际工作流数据验证
- 清晰的调用链路分析

### 问题7：是否已经学习了代码实施的注意事项？
**✅ 已学习**。
- 第17条：插入/更新使用bean，查询使用sql ✅
- 第21条：不使用convertToVo，使用BeanUtils.copyProperties ✅
- 第23条：使用UuidUtil.createShort() ✅

---

## 7. 风险分析和缓解措施

### 7.1 技术风险

| 风险 | 等级 | 缓解措施 |
|------|------|----------|
| 条件分支处理 | 中 | 保留原有ConditionalEdge逻辑，只修改并行/汇聚部分 |
| 异步线程上下文 | 低 | 保留DataSourceHelper.use()调用 |
| 边缘情况遗漏 | 低 | 使用workflow_id=31进行完整测试 |

### 7.2 回滚方案

如果新实现出现问题，可以通过git revert回滚到修改前的状态。

---

## 8. 实施计划

### 8.1 修改步骤

1. 删除`WorkflowEngine`中的错误代码（变量、方法）
2. 重写`buildStateGraph()`方法
3. 添加`processConditionalEdges()`方法
4. 添加`isEndNode()`方法
5. 修改`run()`方法中的调用逻辑

### 8.2 测试验证

使用workflow_id=31（合同审批工作流）进行测试：
- 验证并行分叉正确执行
- 验证汇聚节点等待所有上游完成
- 验证结果正确聚合

---

## 9. 文档元信息

- **创建时间**: 2025-11-30 15:00:00
- **作者**: Claude Code
- **状态**: 待审批
