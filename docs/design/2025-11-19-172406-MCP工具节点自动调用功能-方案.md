# MCP工具节点自动调用功能实施方案

**文档版本**: v1.0
**创建时间**: 2025-11-19 17:24:06
**作者**: zzxxhh
**审批状态**: 待审批

---

## 📋 需求概述

### 核心需求
1. **自动工具调用**: MCP工具节点运行时，LLM能够自动选择并调用对应的MCP工具（基于Function Calling机制）
2. **AI参与错误处理**: MCP工具执行失败时，将异常转换为消息，让LLM理解错误并给出友好回复
3. **参数自动提取**: LLM能够从workflow的上下文（输入变量、对话历史）中自动提取工具所需参数

### 业务价值
- **智能化**: LLM根据用户意图自动选择合适的工具，无需手动配置
- **用户友好**: 工具执行失败时，AI能理解错误并向用户解释，而不是显示技术错误
- **灵活性**: 支持复杂的参数提取，LLM可以从多种上下文来源获取参数

---

## 🔍 KISS原则7问题评估

### 1. "这是个真问题还是臆想出来的？"
✅ **真问题**
- 用户明确需要MCP工具节点能够自动调用工具
- Spring AI的Function Calling机制本身就支持这个能力
- 系统已有@McpTool注解定义的工具（BinMcpTools等），但未启用Function Calling

### 2. "有更简单的方法吗？"
✅ **当前方案已是最简**
- Spring AI提供了开箱即用的Function Calling机制
- 只需启用配置 + 创建ToolCallbackProvider Bean即可
- 不需要手动解析、路由、调用工具
- LLM自动完成参数提取和工具选择

### 3. "会破坏什么吗？"
✅ **零破坏性**
- `workflowDomainChatClient`已经有ToolCallbackProvider注入点（line 109）
- `WorkflowUtil.streamingInvokeLLM()`无需修改
- `McpToolNode.java`无需修改
- 只是"激活"现有基础设施，不改变现有逻辑

### 4. "当前项目真的需要这个功能吗？"
✅ **必要功能**
- 用户明确提出需求
- 是MCP工具节点的核心能力
- 没有这个功能，MCP工具节点无法正常工作

### 5. "这个问题过度设计了吗？有缺少必要信息吗？能否继续评估？"
✅ **设计合理，信息充足**
- 已研究Spring AI文档和示例代码
- 理解了Function Calling的完整工作机制
- 知道如何配置ToolCallbackProvider和错误处理
- 可以明确回答用户的参数提取疑问

### 6. "话题是否模糊，是否会导致幻觉的产生？"
✅ **需求明确，不会产生幻觉**
- 自动调用MCP工具：有Spring AI官方文档支撑
- AI参与错误处理：有ToolExecutionExceptionProcessor接口
- 参数自动提取：这是LLM Function Calling的标准能力

### 7. "是否已经学习了关于代码实施的注意事项的内容？"
✅ **已深入研究**
- 研究了Spring AI的MCP集成机制
- 分析了spring-ai-examples中的brave-chatbot示例
- 理解了现有系统的ToolCallbackProvider注入点
- 知道如何配置错误处理机制

---

## 📊 数据收集与分析

### 现有代码分析

#### 1. AiChatMemoryConfig.java（已有基础设施）
**文件路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/config/memory/AiChatMemoryConfig.java`

**关键代码** (lines 103-123):
```java
@Lazy
@Bean("workflowDomainChatClient")
public ChatClient workflowDomainChatClient(
        AiModelProvider aiModelProvider,
        MessageChatMemoryAdvisor workflowMessageChatMemoryAdvisor,
        WorkflowConversationAdvisor workflowConversationAdvisor,
        @Autowired(required = false) ToolCallbackProvider toolCallbackProvider) {  // 注入点已存在

    ChatModel chatModel = aiModelProvider.getChatModel();
    ChatClient.Builder builder = ChatClient.builder(chatModel)
            .defaultAdvisors(workflowMessageChatMemoryAdvisor, workflowConversationAdvisor);

    // 如果 MCP Client 已启用，注入工具回调
    if (toolCallbackProvider != null) {  // 🔴 关键: 目前 toolCallbackProvider 是 null
        builder.defaultToolCallbacks(toolCallbackProvider);
    }

    return builder.build();
}
```

**发现**:
- ✅ ToolCallbackProvider注入点已存在
- ❌ `@Autowired(required = false)` 说明目前没有Bean，所以是null
- ✅ 只要创建ToolCallbackProvider Bean，Function Calling就会自动启用

#### 2. WorkflowUtil.streamingInvokeLLM（无需修改）
**文件路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/workflow/WorkflowUtil.java`

**关键流程** (lines 119-220):
```java
public static void streamingInvokeLLM(...) {
    // ...
    // 有记忆模式 - 使用 chatWithWorkflowMemoryStream()
    aiChatBaseService.chatWithWorkflowMemoryStream(chatOption, runtimeUuid, originalUserInput)
        .chatResponse()
        .doOnNext(chatResponse -> {
            // 流式处理响应
        })
        .blockLast();
}
```

**发现**:
- ✅ 已经使用 `workflowDomainChatClient`
- ✅ 一旦ToolCallbackProvider存在，LLM自动启用Function Calling
- ✅ 无需修改任何代码

#### 3. 现有MCP工具定义（已存在）
**文件路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/mcp/P00000025/tools/BinMcpTools.java`

**示例工具** (lines 66-75):
```java
@McpTool(description = "查询库位信息，支持按仓库、库区、编码、状态等条件查询库位列表")
public String queryBins(
    @McpToolParam(description = "租户编码") String tenantCode,
    @McpToolParam(description = "仓库ID") Integer warehouseId,
    @McpToolParam(description = "库区ID") Integer locationId,
    // ... 更多参数
) {
    // ...
}
```

**发现**:
- ✅ 已有3个MCP工具类：BinMcpTools、WarehouseMcpTools、LocationMcpTools
- ✅ 使用 `@McpTool` 和 `@McpToolParam` 注解（来自 `org.springaicommunity.mcp.annotation`）
- ❌ 但这些工具未注册到Spring AI的Function Calling机制

#### 4. Spring AI MCP依赖（已引入）
**文件路径**: `scm-ai/pom.xml`

```xml
<!-- Spring AI MCP Client -->
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-starter-mcp-client</artifactId>
</dependency>
```

**发现**:
- ✅ Spring AI MCP Client Starter已引入
- ✅ 根据spring-ai-examples，只需配置 `spring.ai.mcp.client.toolcallback.enabled=true`
- ❌ 但当前配置中未启用

### Spring AI Function Calling工作机制

#### 参数自动提取原理

**场景1：用户提供明确参数**
```
用户输入: "查询仓库ID为123、库区ID为456的库位信息"

LLM自动识别:
- warehouseId = 123 (从用户输入提取)
- locationId = 456 (从用户输入提取)
- tenantCode = null (未提供，使用默认值或null)

LLM调用: queryBins(null, 123, 456)
```

**场景2：workflow变量引用**
```
# McpNodeProperty配置的tool_input
"查询库位信息，条件: {input.query_condition}"

# workflow上游节点输出
{
  "query_condition": "仓库ID为123、库区ID为456"
}

# 实际发送给LLM的prompt (经过WorkflowUtil.renderTemplate)
"查询库位信息，条件: 仓库ID为123、库区ID为456"

LLM自动识别并调用: queryBins(null, 123, 456)
```

**场景3：对话历史中的上下文**
```
对话历史:
用户: "我想查询123号仓库"
AI: "好的，请问要查询什么信息?"
用户: "查询456号库区的库位"

LLM从对话历史中提取:
- warehouseId = 123 (从历史消息)
- locationId = 456 (从当前消息)

LLM调用: queryBins(null, 123, 456)
```

**关键机制**:
1. **工具定义包含参数描述** → LLM知道每个参数的含义
2. **LLM分析整个上下文** → 包括用户输入、workflow变量、对话历史
3. **LLM智能提取参数** → 根据参数描述匹配上下文中的值
4. **自动类型转换** → Spring AI自动将字符串转换为Integer、Long等类型

**✅ 结论：无需手动参数解析，LLM全自动处理**

#### 错误处理机制

Spring AI提供了 `ToolExecutionExceptionProcessor` 接口：

```java
@FunctionalInterface
public interface ToolExecutionExceptionProcessor {
    /**
     * 将工具执行异常转换为可发送给AI的字符串，或重新抛出异常
     */
    String process(ToolExecutionException exception);
}
```

**两种处理模式**:

**模式1：转换为消息（用户需求）**
```java
@Bean
public ToolExecutionExceptionProcessor toolExecutionExceptionProcessor() {
    return new DefaultToolExecutionExceptionProcessor(false);  // false = 转换为消息
}
```
- 工具失败 → 异常转换为文本 → 发送给LLM → LLM理解错误并回复用户
- 用户看到友好解释，而不是技术错误

**模式2：重新抛出（严格控制）**
```java
@Bean
public ToolExecutionExceptionProcessor toolExecutionExceptionProcessor() {
    return new DefaultToolExecutionExceptionProcessor(true);  // true = 总是抛出
}
```
- 工具失败 → 异常重新抛出 → 应用层处理 → 记录日志、返回错误码

---

## 🎯 设计方案

### 核心策略

**问题**: 系统已有 `@McpTool` 注解的工具，但Spring AI的MCP Client Starter期望通过外部MCP Server（stdio/sse）连接

**解决方案**: 不使用Spring AI的自动配置，而是**手动创建ToolCallbackProvider**，将现有@McpTool工具注册为Spring AI的FunctionCallback

### 技术架构

```
┌─────────────────────────────────────────────────────────────┐
│ McpToolNode.java                                            │
│ - onProcess() → WorkflowUtil.streamingInvokeLLM()          │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ WorkflowUtil.streamingInvokeLLM()                           │
│ - aiChatBaseService.chatWithWorkflowMemoryStream()         │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ workflowDomainChatClient                                    │
│ - 已注入 ToolCallbackProvider （🔥 我们要创建的）          │
│ - 自动启用 Function Calling                                 │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ LLM with Function Calling                                   │
│ - 接收工具定义（从ToolCallbackProvider）                    │
│ - 根据prompt智能选择工具                                     │
│ - 从上下文提取参数                                           │
│ - 调用工具                                                   │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼
┌─────────────────────────────────────────────────────────────┐
│ @McpTool Annotated Methods                                  │
│ - BinMcpTools.queryBins()                                   │
│ - WarehouseMcpTools.queryWarehouses()                       │
│ - LocationMcpTools.queryLocations()                         │
└──────────────────┬──────────────────────────────────────────┘
                   │
                   ▼ (成功)
         返回结果给LLM → 生成回答
                   │
                   ▼ (失败)
┌─────────────────────────────────────────────────────────────┐
│ ToolExecutionExceptionProcessor                             │
│ - 转换异常为消息                                             │
│ - 发送给LLM → LLM理解错误并回复用户                          │
└─────────────────────────────────────────────────────────────┘
```

### 实现步骤

#### 步骤1：创建MCP工具配置类

**文件**: `scm-ai/src/main/java/com/xinyirun/scm/ai/config/mcp/McpToolConfig.java`

**职责**:
1. 扫描所有带 `@McpTool` 注解的方法
2. 将它们转换为Spring AI的 `FunctionCallback`
3. 创建 `ToolCallbackProvider` Bean
4. 配置 `ToolExecutionExceptionProcessor` Bean

**核心逻辑**:
```java
@Configuration
public class McpToolConfig {

    @Bean
    public ToolCallbackProvider mcpToolCallbackProvider(ApplicationContext context) {
        // 1. 扫描所有带@Component的Bean
        Map<String, Object> beans = context.getBeansWithAnnotation(Component.class);

        List<FunctionCallback> functionCallbacks = new ArrayList<>();

        for (Object bean : beans.values()) {
            // 2. 扫描每个Bean的@McpTool方法
            for (Method method : bean.getClass().getMethods()) {
                if (method.isAnnotationPresent(McpTool.class)) {
                    // 3. 将@McpTool方法包装为FunctionCallback
                    FunctionCallback callback = createFunctionCallback(bean, method);
                    functionCallbacks.add(callback);
                }
            }
        }

        // 4. 返回ToolCallbackProvider
        return () -> functionCallbacks;
    }

    @Bean
    public ToolExecutionExceptionProcessor toolExecutionExceptionProcessor() {
        // 用户需求：让AI参与错误处理（转换为消息）
        return new DefaultToolExecutionExceptionProcessor(false);
    }
}
```

#### 步骤2：实现FunctionCallback包装器

**职责**: 将 `@McpTool` 方法适配为Spring AI的 `FunctionCallback`

**核心逻辑**:
```java
private FunctionCallback createFunctionCallback(Object bean, Method method) {
    McpTool mcpTool = method.getAnnotation(McpTool.class);

    // 工具名称：类名.方法名
    String name = bean.getClass().getSimpleName() + "." + method.getName();

    // 工具描述：从@McpTool注解
    String description = mcpTool.description();

    // 参数定义：从@McpToolParam注解
    String jsonSchema = buildJsonSchema(method);

    return FunctionCallback.builder()
        .function(name, (input) -> {
            // 反射调用@McpTool方法
            return method.invoke(bean, extractParameters(input, method));
        })
        .description(description)
        .inputTypeSchema(jsonSchema)
        .build();
}
```

#### 步骤3：构建参数JSON Schema

**职责**: 从 `@McpToolParam` 注解构建Function Calling的参数定义

**示例输入**:
```java
@McpTool(description = "查询库位信息")
public String queryBins(
    @McpToolParam(description = "租户编码") String tenantCode,
    @McpToolParam(description = "仓库ID") Integer warehouseId
) { ... }
```

**生成的JSON Schema**:
```json
{
  "type": "object",
  "properties": {
    "tenantCode": {
      "type": "string",
      "description": "租户编码"
    },
    "warehouseId": {
      "type": "integer",
      "description": "仓库ID"
    }
  },
  "required": ["tenantCode"]
}
```

#### 步骤4：参数提取和类型转换

**职责**: 从LLM传递的JSON参数，提取并转换为方法参数

**核心逻辑**:
```java
private Object[] extractParameters(String jsonInput, Method method) {
    JSONObject input = JSON.parseObject(jsonInput);
    Parameter[] parameters = method.getParameters();
    Object[] args = new Object[parameters.length];

    for (int i = 0; i < parameters.length; i++) {
        Parameter param = parameters.i];
        String paramName = param.getName();
        Class<?> paramType = param.getType();

        // 从JSON中提取参数值并转换类型
        args[i] = convertType(input.get(paramName), paramType);
    }

    return args;
}
```

---

## 📁 文件修改清单

### 后端文件

#### 新建文件

1. **McpToolConfig.java** （核心配置类）
   - **路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/config/mcp/McpToolConfig.java`
   - **职责**:
     - 创建ToolCallbackProvider Bean
     - 扫描@McpTool注解的方法
     - 配置ToolExecutionExceptionProcessor
   - **关键方法**:
     - `mcpToolCallbackProvider()` - 创建工具回调提供者
     - `toolExecutionExceptionProcessor()` - 配置错误处理

2. **McpFunctionCallbackAdapter.java** （工具适配器）
   - **路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/config/mcp/McpFunctionCallbackAdapter.java`
   - **职责**:
     - 将@McpTool方法包装为FunctionCallback
     - 构建JSON Schema参数定义
     - 处理参数提取和类型转换
   - **关键方法**:
     - `createFunctionCallback()` - 创建函数回调
     - `buildJsonSchema()` - 构建参数Schema
     - `extractParameters()` - 提取并转换参数

#### 无需修改的文件（只是激活）

1. **AiChatMemoryConfig.java**
   - **路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/config/memory/AiChatMemoryConfig.java`
   - **变化**: 无需修改，`@Autowired(required = false) ToolCallbackProvider` 会自动注入我们创建的Bean

2. **WorkflowUtil.java**
   - **路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/workflow/WorkflowUtil.java`
   - **变化**: 无需修改，自动启用Function Calling

3. **McpToolNode.java**
   - **路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/workflow/node/mcptool/McpToolNode.java`
   - **变化**: 无需修改，注释会自动变为现实

4. **BinMcpTools.java、WarehouseMcpTools.java、LocationMcpTools.java**
   - **路径**: `scm-ai/src/main/java/com/xinyirun/scm/ai/mcp/P00000025/tools/*.java`
   - **变化**: 无需修改，会被自动发现和注册

### 前端文件

**无需修改** - 前端的McpNode.vue和McpNodeProperty.vue已在前一次会话中完成简化。

---

## 🧪 测试策略

### 单元测试

**测试文件**: `McpToolConfigTest.java`

**测试用例**:
1. 验证ToolCallbackProvider Bean创建成功
2. 验证能正确扫描@McpTool注解
3. 验证FunctionCallback包装正确
4. 验证JSON Schema生成正确
5. 验证参数提取和类型转换正确
6. 验证错误处理配置正确

### 集成测试

**测试场景**:

**场景1：明确参数调用**
```
用户输入: "查询仓库ID为1的库位"
期望: LLM调用 queryBins(null, 1, null, ...)
验证: 返回正确的库位列表
```

**场景2：变量引用调用**
```
Workflow配置: tool_input = "查询{input.warehouse_id}号仓库的库位"
上游输出: { "warehouse_id": 2 }
期望: LLM调用 queryBins(null, 2, null, ...)
```

**场景3：对话历史调用**
```
历史消息: "我想查询3号仓库"
当前消息: "显示所有库位"
期望: LLM从历史提取warehouse_id=3并调用
```

**场景4：错误处理**
```
模拟: queryBins抛出异常
期望:
- 异常被捕获
- 转换为消息发送给LLM
- LLM生成友好的错误解释
```

---

## 🚨 风险评估与缓解

### 技术风险

| 风险 | 严重性 | 概率 | 缓解措施 |
|------|--------|------|----------|
| 参数类型转换失败 | 中 | 低 | 实现健壮的类型转换，捕获异常并记录日志 |
| 工具执行超时 | 中 | 中 | 配置合理的超时时间，实现超时降级逻辑 |
| JSON Schema生成错误 | 高 | 低 | 单元测试验证所有参数类型的Schema |
| 租户上下文丢失 | 高 | 中 | 在工具调用前验证租户上下文，必要时重新设置 |

### 性能风险

| 风险 | 严重性 | 概率 | 缓解措施 |
|------|--------|------|----------|
| 工具数量过多导致LLM token消耗大 | 中 | 低 | 目前只有3个工具类，可接受 |
| 工具执行时间长阻塞流式输出 | 中 | 中 | 实现异步工具调用（后续优化）|

### 业务风险

| 风险 | 严重性 | 概率 | 缓解措施 |
|------|--------|------|----------|
| LLM选择错误的工具 | 中 | 低 | 完善工具描述，提供更明确的参数说明 |
| 用户输入参数不完整 | 低 | 中 | LLM会请求用户补充参数 |
| 错误处理不够友好 | 低 | 低 | 测试多种错误场景，优化错误消息 |

---

## 📌 关键决策记录

### 决策1：不使用Spring AI的自动配置
**原因**:
- 系统已有@McpTool注解的工具
- Spring AI的MCP Client Starter期望外部MCP Server
- 手动创建ToolCallbackProvider更灵活，适合现有架构

### 决策2：错误转换为消息（而非抛出）
**原因**:
- 用户明确要求"让AI参与错误处理"
- 提供更好的用户体验
- LLM能够理解错误并给出建议

### 决策3：保留@McpTool注解
**原因**:
- 避免破坏现有代码
- @McpTool注解已被多个工具类使用
- 通过适配器模式兼容Spring AI

### 决策4：工具名称格式为"类名.方法名"
**原因**:
- 避免不同类中方法名重复
- 便于调试和日志追踪
- 符合Java命名习惯

---

## 📖 实施总结

### 核心优势
1. **零破坏性**: 无需修改现有代码，只是激活现有基础设施
2. **最简实现**: 基于Spring AI标准机制，无需自己实现Function Calling
3. **智能化**: LLM自动选择工具、提取参数、理解错误
4. **向后兼容**: 保留@McpTool注解，适配器模式集成

### 实施复杂度
- **新建文件**: 2个（McpToolConfig + McpFunctionCallbackAdapter）
- **修改文件**: 0个
- **代码行数**: 约300行（含注释和测试）
- **预计工时**: 4小时（开发 + 测试）

### 后续优化方向
1. 工具调用异步化（当前同步可能阻塞流式输出）
2. 工具调用缓存（相同参数避免重复调用）
3. 工具执行监控（调用次数、耗时统计）
4. 动态工具加载（运行时添加/删除工具）

---

## ✅ 准备进入实施阶段

本方案已完成以下准备工作：
- ✅ 需求理解确认
- ✅ KISS原则7问题评估
- ✅ 数据收集与分析
- ✅ 技术方案设计
- ✅ 文件修改清单
- ✅ 测试策略
- ✅ 风险评估与缓解

**等待用户审批后进入代码实施阶段**。
