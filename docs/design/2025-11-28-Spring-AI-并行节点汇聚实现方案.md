# Spring AI 并行节点汇聚实现方案 (BiSheng场景1)

## 一、需求场景

类似BiSheng的场景1:两个并行节点汇聚到一个下游节点

```
┌─────────────────────┐
│ 甲方名称合规性审查    │────┐
└─────────────────────┘    │
                          ├──▶ ┌─────────────────────┐
┌─────────────────────┐    │    │ 合规性审查分析       │
│ 乙方名称合规性审查    │────┘    └─────────────────────┘
└─────────────────────┘
```

**核心要求**:
1. 两个审查节点**并行执行**(真正的异步)
2. 下游节点**等待两个节点都完成**后才执行
3. 下游节点能**访问两个上游节点的结果**并合并

## 二、技术选型: Spring AI + Reactor + CompletableFuture

### 2.1 为什么不用LangGraph4j?

当前SCM项目虽然引入了 `langgraph4j`,但你明确要求使用 **Spring AI**。Spring AI 本身没有内置的状态图执行引擎,需要我们自己实现并行汇聚机制。

### 2.2 推荐技术栈

```java
// Spring AI 核心
org.springframework.ai.chat.client.ChatClient
org.springframework.ai.chat.model.ChatModel

// Reactor 响应式编程
reactor.core.publisher.Flux
reactor.core.publisher.Mono

// Java异步并发
java.util.concurrent.CompletableFuture
java.util.concurrent.CompletableFuture.allOf()

// Spring异步支持
@Async
ThreadPoolTaskExecutor
```

## 三、核心实现方案

### 3.1 并行执行模式: CompletableFuture.allOf()

**关键代码**:

```java
/**
 * 并行节点汇聚执行器
 */
@Component
public class ParallelNodeExecutor {

    @Resource
    private ChatClient chatClient;

    @Resource(name = "workflowExecutor")
    private ThreadPoolTaskExecutor workflowExecutor;

    /**
     * 执行并行节点并等待汇聚
     *
     * @param upstreamNodes 上游并行节点列表
     * @param downstreamNode 下游汇聚节点
     * @param workflowState 工作流状态
     * @return 下游节点输出
     */
    public CompletableFuture<NodeOutput> executeParallelAndJoin(
            List<WorkflowNode> upstreamNodes,
            WorkflowNode downstreamNode,
            WorkflowState workflowState) {

        // ===== 第一步: 并行执行所有上游节点 =====
        List<CompletableFuture<NodeOutput>> upstreamFutures = upstreamNodes.stream()
            .map(node -> executeNodeAsync(node, workflowState))
            .toList();

        // ===== 第二步: 使用 allOf 等待所有节点完成 =====
        CompletableFuture<Void> allCompleted = CompletableFuture.allOf(
            upstreamFutures.toArray(new CompletableFuture[0])
        );

        // ===== 第三步: 所有节点完成后,合并结果并执行下游节点 =====
        return allCompleted.thenCompose(v -> {
            // 收集所有上游节点的输出结果
            Map<String, NodeOutput> upstreamResults = new HashMap<>();
            for (int i = 0; i < upstreamNodes.size(); i++) {
                WorkflowNode node = upstreamNodes.get(i);
                NodeOutput output = upstreamFutures.get(i).join(); // join()不会阻塞,因为已经完成
                upstreamResults.put(node.getUuid(), output);
            }

            // 将上游结果存入工作流状态
            workflowState.setParallelResults(upstreamResults);

            // 执行下游汇聚节点
            return executeNodeAsync(downstreamNode, workflowState);
        });
    }

    /**
     * 异步执行单个节点
     */
    private CompletableFuture<NodeOutput> executeNodeAsync(
            WorkflowNode node,
            WorkflowState workflowState) {

        return CompletableFuture.supplyAsync(() -> {
            try {
                // 从工作流状态获取节点输入
                String input = buildNodeInput(node, workflowState);

                // 调用Spring AI ChatClient执行LLM
                String output = chatClient.prompt()
                    .user(input)
                    .call()
                    .content();

                // 返回节点输出
                return new NodeOutput(node.getUuid(), output);

            } catch (Exception e) {
                log.error("节点执行失败: nodeUuid={}", node.getUuid(), e);
                throw new RuntimeException("节点执行失败", e);
            }
        }, workflowExecutor); // 使用自定义线程池
    }
}
```

### 3.2 工作流状态管理

```java
/**
 * 工作流状态 - 存储节点输出和全局变量
 */
@Data
public class WorkflowState {

    /**
     * 节点输出池: nodeUuid -> NodeOutput
     */
    private Map<String, NodeOutput> nodeOutputs = new ConcurrentHashMap<>();

    /**
     * 并行节点结果池: 用于汇聚节点访问多个上游结果
     */
    private Map<String, NodeOutput> parallelResults = new ConcurrentHashMap<>();

    /**
     * 获取节点输出(支持变量引用语法: {nodeUuid.fieldName})
     */
    public String getVariable(String reference) {
        // 解析 nodeUuid.fieldName 格式
        String[] parts = reference.split("\\.", 2);
        String nodeUuid = parts[0];
        String fieldName = parts.length > 1 ? parts[1] : "output";

        // 优先从并行结果池查找
        NodeOutput output = parallelResults.get(nodeUuid);
        if (output == null) {
            output = nodeOutputs.get(nodeUuid);
        }

        if (output == null) {
            throw new RuntimeException("节点输出不存在: " + nodeUuid);
        }

        return output.getField(fieldName);
    }
}

/**
 * 节点输出
 */
@Data
@AllArgsConstructor
public class NodeOutput {
    private String nodeUuid;
    private String content; // 主要输出内容
    private Map<String, Object> fields = new HashMap<>(); // 结构化字段

    public NodeOutput(String nodeUuid, String content) {
        this.nodeUuid = nodeUuid;
        this.content = content;
        this.fields.put("output", content);
    }

    public String getField(String fieldName) {
        Object value = fields.get(fieldName);
        return value != null ? value.toString() : null;
    }
}
```

### 3.3 下游节点如何访问多个上游结果

**示例: 合规性审查分析节点**

```java
/**
 * 合规性审查分析节点配置
 */
{
    "nodeUuid": "compliance-analysis-node",
    "nodeType": "LLM",
    "config": {
        "systemPrompt": "你是一个合同合规性分析专家",
        "userPrompt": """
            请综合分析以下两个审查结果:

            甲方名称合规性审查结果:
            {party-a-check-node.output}

            乙方名称合规性审查结果:
            {party-b-check-node.output}

            请给出综合的合规性分析报告。
        """
    }
}
```

**执行流程**:

```java
// 1. 并行执行两个审查节点
CompletableFuture<NodeOutput> partyAFuture = executeNodeAsync(partyANode, state);
CompletableFuture<NodeOutput> partyBFuture = executeNodeAsync(partyBNode, state);

// 2. 等待所有节点完成
CompletableFuture.allOf(partyAFuture, partyBFuture).join();

// 3. 收集结果到工作流状态
state.getParallelResults().put("party-a-check-node", partyAFuture.join());
state.getParallelResults().put("party-b-check-node", partyBFuture.join());

// 4. 构建下游节点的输入 (解析变量引用)
String analysisInput = """
    请综合分析以下两个审查结果:

    甲方名称合规性审查结果:
    %s

    乙方名称合规性审查结果:
    %s

    请给出综合的合规性分析报告。
""".formatted(
    state.getVariable("party-a-check-node.output"),
    state.getVariable("party-b-check-node.output")
);

// 5. 执行下游汇聚节点
NodeOutput analysisOutput = chatClient.prompt()
    .user(analysisInput)
    .call()
    .content();
```

## 四、流式响应集成

### 4.1 支持SSE流式输出

下游节点可以使用 Spring AI 的流式API:

```java
/**
 * 流式执行汇聚节点
 */
public Flux<String> executeAnalysisNodeStreaming(
        String partyAResult,
        String partyBResult) {

    String prompt = """
        请综合分析以下两个审查结果:

        甲方: %s
        乙方: %s

        请给出综合分析报告。
    """.formatted(partyAResult, partyBResult);

    return chatClient.prompt()
        .user(prompt)
        .stream()
        .content(); // 返回 Flux<String>
}
```

### 4.2 完整的流式工作流执行

```java
/**
 * 工作流流式执行器
 */
@Component
public class WorkflowStreamingExecutor {

    @Resource
    private ParallelNodeExecutor parallelNodeExecutor;

    /**
     * 流式执行包含并行汇聚的工作流
     */
    public Flux<WorkflowEventVo> executeWorkflowStreaming(
            String workflowUuid,
            Map<String, Object> inputs) {

        return Flux.create(sink -> {
            WorkflowState state = new WorkflowState();

            // 1. 并行执行审查节点 (非阻塞)
            sink.next(WorkflowEventVo.createNodeRunEvent("party-a-check", "开始执行"));
            sink.next(WorkflowEventVo.createNodeRunEvent("party-b-check", "开始执行"));

            CompletableFuture<NodeOutput> partyAFuture = executeNodeAsync(partyANode, state);
            CompletableFuture<NodeOutput> partyBFuture = executeNodeAsync(partyBNode, state);

            // 2. 等待并行节点完成
            CompletableFuture.allOf(partyAFuture, partyBFuture)
                .thenAccept(v -> {
                    // 收集结果
                    NodeOutput partyAOutput = partyAFuture.join();
                    NodeOutput partyBOutput = partyBFuture.join();

                    sink.next(WorkflowEventVo.createNodeOutputEvent("party-a-check", partyAOutput.getContent()));
                    sink.next(WorkflowEventVo.createNodeOutputEvent("party-b-check", partyBOutput.getContent()));

                    state.getParallelResults().put("party-a-check", partyAOutput);
                    state.getParallelResults().put("party-b-check", partyBOutput);

                    // 3. 流式执行下游汇聚节点
                    sink.next(WorkflowEventVo.createNodeRunEvent("analysis", "开始分析"));

                    executeAnalysisNodeStreaming(
                        partyAOutput.getContent(),
                        partyBOutput.getContent()
                    ).subscribe(
                        chunk -> sink.next(WorkflowEventVo.createNodeChunkEvent("analysis", chunk)),
                        error -> sink.error(error),
                        () -> {
                            sink.next(WorkflowEventVo.createDoneEvent("工作流执行完成"));
                            sink.complete();
                        }
                    );
                })
                .exceptionally(e -> {
                    sink.error(e);
                    return null;
                });
        });
    }
}
```

## 五、关键技术对比

| 技术点 | BiSheng (LangGraph) | SCM (Spring AI + Reactor) |
|--------|---------------------|---------------------------|
| **并行执行** | LangGraph自动调度(伪并行) | CompletableFuture真正异步并发 |
| **等待机制** | add_edge([list], target) | CompletableFuture.allOf() |
| **状态管理** | GraphState全局变量池 | WorkflowState + ConcurrentHashMap |
| **流式响应** | StreamHandler回调 | Flux响应式流 |
| **数据合并** | 变量引用 `{nodeId.field}` | WorkflowState.getVariable() |

## 六、完整示例代码

### 6.1 定义工作流图

```java
/**
 * 工作流图配置
 */
@Data
public class WorkflowGraph {
    private List<WorkflowNode> nodes;
    private List<WorkflowEdge> edges;

    /**
     * 查找需要并行执行的节点组
     */
    public List<ParallelNodeGroup> findParallelGroups() {
        List<ParallelNodeGroup> groups = new ArrayList<>();

        // 找到所有有多个上游节点的节点(汇聚节点)
        Map<String, List<String>> targetToSources = new HashMap<>();
        for (WorkflowEdge edge : edges) {
            targetToSources.computeIfAbsent(edge.getTargetNodeUuid(), k -> new ArrayList<>())
                .add(edge.getSourceNodeUuid());
        }

        // 识别并行组
        for (Map.Entry<String, List<String>> entry : targetToSources.entrySet()) {
            if (entry.getValue().size() > 1) {
                // 找到汇聚节点
                String joinNodeUuid = entry.getKey();
                WorkflowNode joinNode = findNodeByUuid(joinNodeUuid);

                // 找到所有上游节点
                List<WorkflowNode> upstreamNodes = entry.getValue().stream()
                    .map(this::findNodeByUuid)
                    .toList();

                // 检查是否是真正的并行(不是互斥分支)
                if (isReallyParallel(upstreamNodes, joinNode)) {
                    groups.add(new ParallelNodeGroup(upstreamNodes, joinNode));
                }
            }
        }

        return groups;
    }

    /**
     * 判断是否是真正的并行(不是condition分支汇聚)
     */
    private boolean isReallyParallel(List<WorkflowNode> upstreamNodes, WorkflowNode joinNode) {
        // 简化判断: 如果所有上游节点都不是condition节点,则认为是真正并行
        return upstreamNodes.stream()
            .noneMatch(node -> "CONDITION".equals(node.getNodeType()));
    }
}

@Data
@AllArgsConstructor
class ParallelNodeGroup {
    private List<WorkflowNode> upstreamNodes;
    private WorkflowNode joinNode;
}
```

### 6.2 工作流执行引擎

```java
/**
 * Spring AI工作流执行引擎
 */
@Component
@Slf4j
public class SpringAIWorkflowEngine {

    @Resource
    private ChatClient chatClient;

    @Resource(name = "workflowExecutor")
    private ThreadPoolTaskExecutor executor;

    /**
     * 执行工作流
     */
    public Flux<WorkflowEventVo> execute(WorkflowGraph graph, Map<String, Object> inputs) {
        return Flux.create(sink -> {
            WorkflowState state = new WorkflowState();
            state.setInputs(inputs);

            try {
                // 识别并行组
                List<ParallelNodeGroup> parallelGroups = graph.findParallelGroups();

                // 执行工作流
                executeWorkflow(graph, state, parallelGroups, sink);

            } catch (Exception e) {
                log.error("工作流执行失败", e);
                sink.error(e);
            }
        });
    }

    /**
     * 执行工作流核心逻辑
     */
    private void executeWorkflow(
            WorkflowGraph graph,
            WorkflowState state,
            List<ParallelNodeGroup> parallelGroups,
            FluxSink<WorkflowEventVo> sink) {

        // 拓扑排序节点执行顺序
        List<WorkflowNode> sortedNodes = topologicalSort(graph);

        for (WorkflowNode node : sortedNodes) {
            // 检查是否属于某个并行组
            ParallelNodeGroup parallelGroup = findParallelGroup(node, parallelGroups);

            if (parallelGroup != null && parallelGroup.getJoinNode().equals(node)) {
                // 这是汇聚节点,执行并行等待逻辑
                executeParallelJoin(parallelGroup, state, sink);
            } else if (isInParallelGroup(node, parallelGroups)) {
                // 这是并行组的上游节点,稍后会被并行执行,跳过
                continue;
            } else {
                // 普通节点,顺序执行
                executeNode(node, state, sink);
            }
        }

        sink.next(WorkflowEventVo.createDoneEvent("工作流执行完成"));
        sink.complete();
    }

    /**
     * 执行并行汇聚
     */
    private void executeParallelJoin(
            ParallelNodeGroup group,
            WorkflowState state,
            FluxSink<WorkflowEventVo> sink) {

        List<WorkflowNode> upstreamNodes = group.getUpstreamNodes();
        WorkflowNode joinNode = group.getJoinNode();

        // 并行执行所有上游节点
        List<CompletableFuture<NodeOutput>> futures = upstreamNodes.stream()
            .map(node -> {
                sink.next(WorkflowEventVo.createNodeRunEvent(node.getUuid(), "开始执行"));
                return executeNodeAsync(node, state);
            })
            .toList();

        // 等待所有节点完成
        CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
            .thenAccept(v -> {
                // 收集结果
                for (int i = 0; i < upstreamNodes.size(); i++) {
                    WorkflowNode node = upstreamNodes.get(i);
                    NodeOutput output = futures.get(i).join();

                    state.getNodeOutputs().put(node.getUuid(), output);
                    state.getParallelResults().put(node.getUuid(), output);

                    sink.next(WorkflowEventVo.createNodeOutputEvent(node.getUuid(), output.getContent()));
                }

                // 执行汇聚节点
                executeNode(joinNode, state, sink);
            })
            .join(); // 阻塞等待(因为后续节点依赖此节点)
    }

    /**
     * 异步执行节点
     */
    private CompletableFuture<NodeOutput> executeNodeAsync(
            WorkflowNode node,
            WorkflowState state) {

        return CompletableFuture.supplyAsync(() -> {
            String input = buildNodeInput(node, state);

            String output = chatClient.prompt()
                .user(input)
                .call()
                .content();

            return new NodeOutput(node.getUuid(), output);
        }, executor);
    }

    /**
     * 同步执行节点
     */
    private void executeNode(
            WorkflowNode node,
            WorkflowState state,
            FluxSink<WorkflowEventVo> sink) {

        sink.next(WorkflowEventVo.createNodeRunEvent(node.getUuid(), "开始执行"));

        String input = buildNodeInput(node, state);

        String output = chatClient.prompt()
            .user(input)
            .call()
            .content();

        NodeOutput nodeOutput = new NodeOutput(node.getUuid(), output);
        state.getNodeOutputs().put(node.getUuid(), nodeOutput);

        sink.next(WorkflowEventVo.createNodeOutputEvent(node.getUuid(), output));
    }

    /**
     * 构建节点输入(解析变量引用)
     */
    private String buildNodeInput(WorkflowNode node, WorkflowState state) {
        String template = node.getConfig().getUserPrompt();

        // 解析 {nodeUuid.field} 格式的变量引用
        Pattern pattern = Pattern.compile("\\{([^}]+)\\}");
        Matcher matcher = pattern.matcher(template);

        StringBuffer sb = new StringBuffer();
        while (matcher.find()) {
            String variable = matcher.group(1);
            String value = state.getVariable(variable);
            matcher.appendReplacement(sb, Matcher.quoteReplacement(value));
        }
        matcher.appendTail(sb);

        return sb.toString();
    }
}
```

## 七、线程池配置

```java
/**
 * 工作流异步执行线程池配置
 */
@Configuration
public class WorkflowExecutorConfig {

    @Bean(name = "workflowExecutor")
    public ThreadPoolTaskExecutor workflowExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(10);
        executor.setMaxPoolSize(50);
        executor.setQueueCapacity(100);
        executor.setThreadNamePrefix("workflow-");
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        executor.initialize();
        return executor;
    }
}
```

## 八、总结

### 8.1 核心技术点

1. **并行执行**: 使用 `CompletableFuture` 实现真正的异步并发
2. **等待机制**: 使用 `CompletableFuture.allOf()` 实现 JOIN 语义
3. **状态管理**: 使用 `ConcurrentHashMap` 存储节点输出,支持并发访问
4. **流式响应**: 使用 `Flux` 集成 Spring AI 的流式API
5. **变量引用**: 解析 `{nodeUuid.field}` 语法,实现节点间数据传递

### 8.2 优势

1. **真正并发**: CompletableFuture 比 LangGraph 的伪并行性能更好
2. **原生Spring**: 无需引入额外的状态图框架
3. **类型安全**: Java强类型系统,编译期检查
4. **易于调试**: 标准Java异步编程模式,工具支持好

### 8.3 后续优化

1. **异常处理**: 增强并行节点的异常隔离和重试
2. **超时控制**: 为每个节点设置执行超时
3. **监控指标**: 记录节点执行时间和并行度
4. **动态调度**: 根据节点依赖自动识别并行机会
